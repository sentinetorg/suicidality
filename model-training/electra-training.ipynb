{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328678be-9ee1-453e-9e63-fc89c5742e21",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3239a6-1b49-44b8-9afb-f59f7d243670",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SOURCE = \"datasets/extracted/dataset-cleaned.csv\"\n",
    "\n",
    "# TRAINING CONFIGS\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 6\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 7984\n",
    "\n",
    "MODEL_SAVE_PATH = \"models/sucidality\"\n",
    "MODEL_CHECKPOINT_PATH = \"models/sucidality-checkpoint\"\n",
    "MODEL_LOGGING_PATH = \"models/sucidality-checkpoint/logs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248b330-fb83-4290-b726-186b84c3bcf6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6921014-9e6f-4fff-bc45-e347545c5426",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f33ac7-2790-46f9-86fd-cce261f6b8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/ubuntu/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda3/lib/python3.11/site-packages (4.31.0)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/miniconda3/lib/python3.11/site-packages (2.14.4)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/lib/python3.11/site-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/miniconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from accelerate>=0.20.3->transformers) (5.9.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/miniconda3/lib/python3.11/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers transformers[torch] datasets numpy pandas scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57728903-94d7-4f70-858e-6a28709dab22",
   "metadata": {},
   "source": [
    "## Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb84ef6-be41-4df0-9146-428c817a698c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\npartially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/aiohttp/client_reqrep.py:70\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcchardet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cchardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1099\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:162\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available():\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.14.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:68\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/data_files.py:9\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_fs_token_paths\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimplementations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPFileSystem\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfFileSystem\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/fsspec/implementations/http.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlparse\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maiohttp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/aiohttp/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hdrs \u001b[38;5;28;01mas\u001b[39;00m hdrs\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     BaseConnector \u001b[38;5;28;01mas\u001b[39;00m BaseConnector,\n\u001b[1;32m      8\u001b[0m     ClientConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m      9\u001b[0m     ClientConnectorCertificateError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[1;32m     10\u001b[0m     ClientConnectorError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorError,\n\u001b[1;32m     11\u001b[0m     ClientConnectorSSLError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorSSLError,\n\u001b[1;32m     12\u001b[0m     ClientError \u001b[38;5;28;01mas\u001b[39;00m ClientError,\n\u001b[1;32m     13\u001b[0m     ClientHttpProxyError \u001b[38;5;28;01mas\u001b[39;00m ClientHttpProxyError,\n\u001b[1;32m     14\u001b[0m     ClientOSError \u001b[38;5;28;01mas\u001b[39;00m ClientOSError,\n\u001b[1;32m     15\u001b[0m     ClientPayloadError \u001b[38;5;28;01mas\u001b[39;00m ClientPayloadError,\n\u001b[1;32m     16\u001b[0m     ClientProxyConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientProxyConnectionError,\n\u001b[1;32m     17\u001b[0m     ClientRequest \u001b[38;5;28;01mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     18\u001b[0m     ClientResponse \u001b[38;5;28;01mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     19\u001b[0m     ClientResponseError \u001b[38;5;28;01mas\u001b[39;00m ClientResponseError,\n\u001b[1;32m     20\u001b[0m     ClientSession \u001b[38;5;28;01mas\u001b[39;00m ClientSession,\n\u001b[1;32m     21\u001b[0m     ClientSSLError \u001b[38;5;28;01mas\u001b[39;00m ClientSSLError,\n\u001b[1;32m     22\u001b[0m     ClientTimeout \u001b[38;5;28;01mas\u001b[39;00m ClientTimeout,\n\u001b[1;32m     23\u001b[0m     ClientWebSocketResponse \u001b[38;5;28;01mas\u001b[39;00m ClientWebSocketResponse,\n\u001b[1;32m     24\u001b[0m     ContentTypeError \u001b[38;5;28;01mas\u001b[39;00m ContentTypeError,\n\u001b[1;32m     25\u001b[0m     Fingerprint \u001b[38;5;28;01mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     26\u001b[0m     InvalidURL \u001b[38;5;28;01mas\u001b[39;00m InvalidURL,\n\u001b[1;32m     27\u001b[0m     NamedPipeConnector \u001b[38;5;28;01mas\u001b[39;00m NamedPipeConnector,\n\u001b[1;32m     28\u001b[0m     RequestInfo \u001b[38;5;28;01mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     29\u001b[0m     ServerConnectionError \u001b[38;5;28;01mas\u001b[39;00m ServerConnectionError,\n\u001b[1;32m     30\u001b[0m     ServerDisconnectedError \u001b[38;5;28;01mas\u001b[39;00m ServerDisconnectedError,\n\u001b[1;32m     31\u001b[0m     ServerFingerprintMismatch \u001b[38;5;28;01mas\u001b[39;00m ServerFingerprintMismatch,\n\u001b[1;32m     32\u001b[0m     ServerTimeoutError \u001b[38;5;28;01mas\u001b[39;00m ServerTimeoutError,\n\u001b[1;32m     33\u001b[0m     TCPConnector \u001b[38;5;28;01mas\u001b[39;00m TCPConnector,\n\u001b[1;32m     34\u001b[0m     TooManyRedirects \u001b[38;5;28;01mas\u001b[39;00m TooManyRedirects,\n\u001b[1;32m     35\u001b[0m     UnixConnector \u001b[38;5;28;01mas\u001b[39;00m UnixConnector,\n\u001b[1;32m     36\u001b[0m     WSServerHandshakeError \u001b[38;5;28;01mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     37\u001b[0m     request \u001b[38;5;28;01mas\u001b[39;00m request,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcookiejar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CookieJar \u001b[38;5;28;01mas\u001b[39;00m CookieJar, DummyCookieJar \u001b[38;5;28;01mas\u001b[39;00m DummyCookieJar\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/aiohttp/client.py:59\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     ClientConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m     40\u001b[0m     ClientConnectorCertificateError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     WSServerHandshakeError \u001b[38;5;28;01mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_reqrep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     ClientRequest \u001b[38;5;28;01mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     61\u001b[0m     ClientResponse \u001b[38;5;28;01mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     62\u001b[0m     Fingerprint \u001b[38;5;28;01mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     63\u001b[0m     RequestInfo \u001b[38;5;28;01mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     64\u001b[0m     _merge_ssl_params,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_ws\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientWebSocketResponse \u001b[38;5;28;01mas\u001b[39;00m ClientWebSocketResponse\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/aiohttp/client_reqrep.py:72\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[no-redef]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClientRequest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClientResponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequestInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFingerprint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/charset_normalizer/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/charset_normalizer/api.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict, load_metric\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1089\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1089\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1101\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\npartially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac53e2-6ba7-4c4e-b3a7-40afdc5d4886",
   "metadata": {},
   "source": [
    "## Load cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae935922-e66c-42cd-9810-0057544dbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATASET_SOURCE, lineterminator='\\n')\n",
    "ds = ds[['cleaned', 'class']]\n",
    "ds = ds.rename(columns={'cleaned': 'text', 'class': 'label'})\n",
    "ds = ds.dropna()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f8454-e359-433a-a0ec-be6f55e10795",
   "metadata": {},
   "source": [
    "## Split dataset for training, evaluation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a61b1d6-9ff7-4bf5-86ec-746781b2d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                     text  label\n",
       " 156594  consider buy gun want die live state get gun e...      1\n",
       " 116160  game thingie explain happen game lose billion ...      0\n",
       " 128769                                 feel sad feel well      0\n",
       " 1202    not understand college coach not run ball dump...      0\n",
       " 240691  want know bear pain want normal die tired way ...      1\n",
       " ...                                                   ...    ...\n",
       " 142070  jewish new year eve year tough wish good new y...      0\n",
       " 215373  vegan teacher got ban celebrate no soggy tit s...      0\n",
       " 85      wish relate read post help feel like write hop...      1\n",
       " 179933     get commitment issue try fix tell somebody get      0\n",
       " 153753             spineless moronic fucking matter tired      1\n",
       " \n",
       " [209613 rows x 2 columns],\n",
       "                                                      text  label\n",
       " 169025  fight boyfriend stay parent house not want sta...      1\n",
       " 138009  mon pass away past summer good friend move far...      1\n",
       " 246671            potato famine want mashed potato hungry      0\n",
       " 208491                                     have great day      0\n",
       " 103511  suddenly turn min craft skin screw llama hard ...      0\n",
       " ...                                                   ...    ...\n",
       " 207860                   want suck dick like no homo shit      0\n",
       " 194211  life bad not benefit rational euthanasia not m...      1\n",
       " 90073   sound sewer slide ill day tired exist tired ob...      1\n",
       " 74284   guy gal need help friend depressed want commit...      0\n",
       " 79876                          shit post writer block art      0\n",
       " \n",
       " [52404 rows x 2 columns],\n",
       "                                                      text  label\n",
       " 51481   get wisdom tooth today honestly want bad think...      0\n",
       " 228719  install shade rob lox play phantom force fukie...      0\n",
       " 239160  rude distant recently sorry nervous wreck like...      0\n",
       " 213179  high school graduation week not go college alc...      1\n",
       " 202638                                        go hang bye      1\n",
       " ...                                                   ...    ...\n",
       " 165620  texte crush good friend photo conversation old...      0\n",
       " 165483  week go gun kill doctor single work prison sex...      1\n",
       " 153026  real world man pretend not order win woman hea...      1\n",
       " 179367  go dinner abdul time meet heck nervous hope no...      0\n",
       " 6479    not enjoy anymore play video game watch show f...      1\n",
       " \n",
       " [26202 rows x 2 columns],\n",
       "                                                      text  label\n",
       " 8153    day planet earth love community decide tonight...      1\n",
       " 219656  girlfriend break text not text tell tell frien...      0\n",
       " 170883  lmaolmabsjdbbsjxbwnxhhdjsshdcmwbdjjf jrhdsndhd...      0\n",
       " 93249   hate revenue hate want die feel blood boiling ...      0\n",
       " 76659                             dog log dog log dog log      0\n",
       " ...                                                   ...    ...\n",
       " 163523  way able push suicide numb drug pill section t...      1\n",
       " 52006   bored fact d weird fact fillererereerususvsgwi...      0\n",
       " 219717  today dad die car accident family income drop ...      0\n",
       " 233539  no hope purpose bitter second feel purposeless...      1\n",
       " 50416   hate want die spend day hate hate feel like sh...      0\n",
       " \n",
       " [26202 rows x 2 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, temp = train_test_split(ds, random_state=SEED, test_size=0.2, stratify=ds['label'])\n",
    "val, test = train_test_split(temp, random_state=SEED, test_size=0.5, stratify=temp['label'])\n",
    "\n",
    "train, temp, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28798e9e-15d4-4288-a4a7-d0afba3365c2",
   "metadata": {},
   "source": [
    "# Setup Model & tokenize the input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a34647a-bea3-48d7-b688-f49d533679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baeeeb6b-73a1-45d8-809b-9d8a93033d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gooohjy/suicidal-electra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a448be-de20-48b0-9231-c825884283de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 209613\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 26202\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 26202\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset_conversion(train, test, val):\n",
    "  \"\"\"Converts pandas dataframe to Dataset.\"\"\"\n",
    "\n",
    "  train.reset_index(drop=True, inplace=True)\n",
    "  test.reset_index(drop=True, inplace=True)\n",
    "  val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  train_dataset = Dataset.from_pandas(train)\n",
    "  test_dataset = Dataset.from_pandas(test)\n",
    "  val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "  return DatasetDict({\"train\": train_dataset, \"test\": test_dataset, \"val\": val_dataset})\n",
    "\n",
    "raw_datasets = dataset_conversion(train, test, val)\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f79d26-2325-41fd-af22-e9c8bdc11e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 209613/209613 [01:00<00:00, 3483.06 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26202/26202 [00:07<00:00, 3459.69 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26202/26202 [00:07<00:00, 3534.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 209613\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 26202\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 26202\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=False)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa384f-10c0-4683-8552-bb1982b090f0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f3d5f-a7eb-405d-a2ec-db0421d9c7fc",
   "metadata": {},
   "source": [
    "## Load the model & trainer methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e940d65d-6a1f-401e-811e-5b45257c0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"gooohjy/suicidal-electra\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c78f6757-ea6b-415a-9116-ce7fdee7dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom metrics for computation\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    metric_rec = load_metric(\"recall\")\n",
    "    metric_pre = load_metric(\"precision\")\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    recall = metric_rec.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    precision = metric_pre.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "\n",
    "    return {'accuracy': accuracy, 'recall': recall, 'precision': precision, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e16862a-abb0-4e01-834f-28db91d1b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and training parameters\n",
    "\n",
    "def get_trainer(datasets, epochs=EPOCHS):\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=MODEL_CHECKPOINT_PATH,\n",
    "        overwrite_output_dir = True,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        seed=SEED,\n",
    "        # evaluation_strategy=\"epoch\",\n",
    "        logging_dir=MODEL_LOGGING_PATH,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1500\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets['train'],\n",
    "        eval_dataset=datasets['val'],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb30a1-70c9-40cb-9cef-b4c26b28e7c2",
   "metadata": {},
   "source": [
    "## Train a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "590ce91d-8984-4f2f-9873-507ab90fef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 20\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 20\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 20\n",
       " })}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SIZE = 20\n",
    "\n",
    "sample = {\n",
    "    'train': tokenized_datasets['train'].shuffle(seed=SEED).select(range(SAMPLE_SIZE)),\n",
    "    'test': tokenized_datasets['test'].shuffle(seed=SEED).select(range(SAMPLE_SIZE)),\n",
    "    'val': tokenized_datasets['val'].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "}\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c64cd83-0ac7-4f0f-9616-d95d76c8b842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.2119610346417175e-07, metrics={'train_runtime': 3.1428, 'train_samples_per_second': 31.819, 'train_steps_per_second': 6.364, 'total_flos': 26311105536000.0, 'train_loss': 1.2119610346417175e-07, 'epoch': 5.0})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = get_trainer(sample)\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5dfaf187-e65a-44e8-8f4e-3941604416e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE TEST RESULTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.842932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>0.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>41.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>8.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SAMPLE TEST RESULTS\n",
       "eval_loss                           0.842932\n",
       "eval_accuracy                       0.950000\n",
       "eval_recall                         0.909091\n",
       "eval_precision                      1.000000\n",
       "eval_f1                             0.952381\n",
       "eval_runtime                        0.478900\n",
       "eval_samples_per_second            41.760000\n",
       "eval_steps_per_second               8.352000\n",
       "epoch                               5.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = trainer.evaluate()\n",
    "\n",
    "pd.DataFrame(data=result, index=['SAMPLE TEST RESULTS']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba69f12-8419-4e36-a68e-085c60a0c9c1",
   "metadata": {},
   "source": [
    "## Train model with the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122fb3f-8913-4d04-b43d-a7b9b588d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12046' max='174680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 12046/174680 37:09 < 8:21:39, 5.40 it/s, Epoch 0.34/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.266700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.326700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.317300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.301500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.282200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.289500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = get_trainer(tokenized_datasets)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66f8f3-52ac-4ecb-a455-621b5c36c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.evaluate()\n",
    "pd.DataFrame(data=result, index=['SAMPLE TEST RESULTS']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036b67e-e903-46fa-bd47-8b5fac201343",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ed21f-c392-4d80-8c04-8030a75da593",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
